{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Any, Sequence, Union\n",
    "\n",
    "import lightning as L\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from lightning.pytorch.utilities.types import STEP_OUTPUT, OptimizerLRScheduler\n",
    "from torchvision.datasets.cifar import CIFAR10\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models.unet import DiffusionUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightingDiffusion(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        T: int = 1000,\n",
    "        beta_start: float = 1e-4,\n",
    "        beta_end: float = 0.02,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = DiffusionUNet()\n",
    "        self.T = T\n",
    "        betas = torch.linspace(beta_start, beta_end, T)\n",
    "        alphas = torch.ones_like(betas) - betas\n",
    "        alpha_bars = torch.cumprod(\n",
    "            alphas, dim=0,\n",
    "        )  # zero indexed\n",
    "        sqrt_one_minus_alpha_bars = torch.sqrt(1.0 - alpha_bars)\n",
    "        \n",
    "        # Register as buffers to move to correct device automatically\n",
    "        self.register_buffer('betas', betas)\n",
    "        self.register_buffer('alphas', alphas)\n",
    "        self.register_buffer('alpha_bars', alpha_bars)\n",
    "        self.register_buffer('sqrt_one_minus_alpha_bars', sqrt_one_minus_alpha_bars)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        batch = batch[0]  # remove label information\n",
    "        \n",
    "        # Sample random values from 0 to T - 1\n",
    "        batch_size = batch.shape[0]\n",
    "        # print('batch shape', batch.shape)\n",
    "        t_batch = torch.randint(0, self.T, (batch_size,), device=self.device)\n",
    "        # print('t batch shape', t_batch.shape)\n",
    "\n",
    "        assert batch.shape[0] == t_batch.shape[0]\n",
    "\n",
    "        # print(\"t_shape\", t_batch.shape)\n",
    "\n",
    "        noise = torch.randn_like(batch)\n",
    "        alpha_bars_batch = self.alpha_bars[t_batch].view(batch_size, 1, 1, 1)\n",
    "        sqrt_one_minus_alpha_bars_batch = self.sqrt_one_minus_alpha_bars[t_batch].view(\n",
    "            batch_size, 1, 1, 1\n",
    "        )\n",
    "\n",
    "        noised_batch = (\n",
    "            alpha_bars_batch * batch + sqrt_one_minus_alpha_bars_batch * noise\n",
    "        )\n",
    "\n",
    "        # print(\"moised batch shape\", noised_batch.shape)\n",
    "        # print(\"t batch shape\", t_batch.shape)\n",
    "        pred_noise = self.model(\n",
    "            noised_batch,\n",
    "            t_batch,\n",
    "        )\n",
    "\n",
    "        loss = torch.nn.functional.mse_loss(noise, pred_noise)\n",
    "\n",
    "        self.log(\n",
    "            \"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def sample_ddpm(self, n_imgs: int, img_size: int):\n",
    "        \"\"\"\n",
    "        Use DDPM iterative sampling to generate a batch of new images (B x 3 x size x size)\n",
    "        \"\"\"\n",
    "        \n",
    "        x_t = torch.randn((n_imgs, 3, img_size, img_size))\n",
    "        with torch.no_grad():\n",
    "            for t in tqdm(reversed(range(self.T))):\n",
    "                t_tensor = torch.ones(n_imgs) * t\n",
    "                z = torch.randn_like(x_t) if t > 0 else torch.zeros_like(x_t)\n",
    "                \n",
    "                pred_denoise = self.model(x_t, t_tensor)\n",
    "                \n",
    "                alpha_t = self.alphas[t]\n",
    "                alpha_bar_t = self.alpha_bars[t]\n",
    "                beta_t = self.betas[t]\n",
    "                \n",
    "                x_next = x_t - (1 - alpha_t) / torch.sqrt(1 - alpha_bar_t) * pred_denoise\n",
    "                \n",
    "                x_t = 1 / torch.sqrt(alpha_t) * x_next + beta_t ** 0.5 * z\n",
    "        return x_t\n",
    "\n",
    "    def sample_ddim(self):\n",
    "        \"\"\"\n",
    "        Sample from the model using DDIM: adjust standard deviation accordingly\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def configure_optimizers(self) -> OptimizerLRScheduler:\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=2e-4)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/avaliveru/miniforge3/envs/diffusion/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:67: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "\n",
      "  | Name  | Type          | Params\n",
      "----------------------------------------\n",
      "0 | model | DiffusionUNet | 168 M \n",
      "----------------------------------------\n",
      "168 M     Trainable params\n",
      "0         Non-trainable params\n",
      "168 M     Total params\n",
      "675.544   Total estimated model params size (MB)\n",
      "/Users/avaliveru/miniforge3/envs/diffusion/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   2%|‚ñè         | 9/391 [00:24<17:39,  0.36it/s, v_num=1, train_loss_step=0.379]  "
     ]
    }
   ],
   "source": [
    "diffusion = LightingDiffusion()\n",
    "\n",
    "# setup data for MNIST\n",
    "torchvision.datasets.CIFAR10.url = torchvision.datasets.CIFAR10.url.replace(\n",
    "    \"https://\", \"http://\"\n",
    ")\n",
    "dataset = torchvision.datasets.CIFAR10(\n",
    "    os.path.dirname(os.getcwd()) + \"/data\",\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=128)\n",
    "\n",
    "# train the model (hint: here are some helpful Trainer arguments for rapid idea iteration)\n",
    "trainer = L.Trainer(max_epochs=1, default_root_dir=os.getcwd() + \"/../results\")\n",
    "trainer.fit(model=diffusion, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diffusion = LightingDiffusion.load_from_checkpoint(\n",
    "#     \"../results/lightning_logs/version_1/checkpoints/epoch=0-step=391.ckpt\"\n",
    "# )\n",
    "\n",
    "# diffusion.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Placeholder storage has not been allocated on MPS device!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m diffusion\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m----> 2\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mdiffusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_ddpm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 72\u001b[0m, in \u001b[0;36mLightingDiffusion.sample_ddpm\u001b[0;34m(self, n_imgs, img_size)\u001b[0m\n\u001b[1;32m     69\u001b[0m t_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(n_imgs) \u001b[38;5;241m*\u001b[39m t\n\u001b[1;32m     70\u001b[0m z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(x_t) \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mzeros_like(x_t)\n\u001b[0;32m---> 72\u001b[0m pred_denoise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m alpha_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malphas[t]\n\u001b[1;32m     75\u001b[0m alpha_bar_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha_bars[t]\n",
      "File \u001b[0;32m~/miniforge3/envs/diffusion/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/diffusion/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/DeepLearning/DiffusionFromScratch/src/models/unet.py:240\u001b[0m, in \u001b[0;36mDiffusionUNet.forward\u001b[0;34m(self, img, t)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, img: torch\u001b[38;5;241m.\u001b[39mTensor, t: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 240\u001b[0m     emb_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(img)\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# Downsample\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/diffusion/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/diffusion/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/DeepLearning/DiffusionFromScratch/src/models/unet.py:39\u001b[0m, in \u001b[0;36mSinusoidalEmbedding.forward\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     36\u001b[0m emb \u001b[38;5;241m=\u001b[39m t[:, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m emb[\u001b[38;5;28;01mNone\u001b[39;00m, :]\n\u001b[1;32m     37\u001b[0m emb \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([torch\u001b[38;5;241m.\u001b[39msin(emb), torch\u001b[38;5;241m.\u001b[39mcos(emb)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[43m(\u001b[49m\u001b[43memb\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m emb\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (t\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memb_dim)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m emb\n",
      "File \u001b[0;32m~/miniforge3/envs/diffusion/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/diffusion/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/diffusion/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Placeholder storage has not been allocated on MPS device!"
     ]
    }
   ],
   "source": [
    "diffusion.eval()\n",
    "img = diffusion.sample_ddpm(256, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16a33e590>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(256, )\n",
    "plt.imshow(img[0].permute(1, 2, 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
